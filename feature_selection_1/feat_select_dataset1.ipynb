{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 4383 x 92</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>H_IDNUMBER</th><th scope=col>HHNO</th><th scope=col>BEM_ID</th><th scope=col>DIST</th><th scope=col>TMEM</th><th scope=col>Q1</th><th scope=col>G1_4S1</th><th scope=col>G1_5A1S1</th><th scope=col>G1_6S1</th><th scope=col>P1A_2A</th><th scope=col>...</th><th scope=col>P12_1</th><th scope=col>P12_2</th><th scope=col>P12_3</th><th scope=col>Q1_1</th><th scope=col>Q1_3</th><th scope=col>Q1_5</th><th scope=col>Q1_6</th><th scope=col>Q1_11</th><th scope=col>Q1_12</th><th scope=col>Q1_13</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>...</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>10_164_3169</td><td>3169</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  20</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td></tr>\n",
              "\t<tr><td>11_164_1386</td><td>1386</td><td>203</td><td>86</td><td>  11</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>   6</td><td>...</td><td>1998</td><td>  91.4</td><td>   1</td><td>   3</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>11_164_1410</td><td>1410</td><td>203</td><td>86</td><td>  12</td><td>1</td><td>1999</td><td>  26</td><td>   2</td><td>  24</td><td>...</td><td>2004</td><td>  91.0</td><td>   3</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   1</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>11_164_1433</td><td>1433</td><td>203</td><td>86</td><td>   8</td><td>1</td><td>1995</td><td>  33</td><td>   1</td><td>  10</td><td>...</td><td>2004</td><td>  97.0</td><td>   2</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td></tr>\n",
              "\t<tr><td>11_164_1456</td><td>1456</td><td>203</td><td>86</td><td>   4</td><td>1</td><td>2011</td><td>  59</td><td>   1</td><td>   6</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>11_164_1480</td><td>1480</td><td>203</td><td>86</td><td>   4</td><td>1</td><td>2002</td><td>  26</td><td>   1</td><td>  10</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>11_164_1503</td><td>1503</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>2008</td><td>  26</td><td>   1</td><td>  20</td><td>...</td><td>2004</td><td>  45.0</td><td>   1</td><td>   1</td><td>   2</td><td>   2</td><td>   1</td><td>   3</td><td>   2</td><td>   2</td></tr>\n",
              "\t<tr><td>11_164_1526</td><td>1526</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  12</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   2</td></tr>\n",
              "\t<tr><td>11_164_1550</td><td>1550</td><td>203</td><td>86</td><td>   6</td><td>1</td><td>2012</td><td>  26</td><td>   1</td><td>   6</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td></tr>\n",
              "\t<tr><td>11_164_1573</td><td>1573</td><td>203</td><td>86</td><td>   8</td><td>1</td><td>2002</td><td>   6</td><td>   2</td><td>   5</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>11_164_1596</td><td>1596</td><td>203</td><td>86</td><td>  12</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  10</td><td>...</td><td>1998</td><td>  30.0</td><td>   1</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   2</td></tr>\n",
              "\t<tr><td>11_164_1620</td><td>1620</td><td>203</td><td>86</td><td>  10</td><td>1</td><td>2016</td><td>  26</td><td>   1</td><td>  12</td><td>...</td><td>2004</td><td>  45.0</td><td>   3</td><td>   2</td><td>   2</td><td>   2</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>11_164_1643</td><td>1643</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>   4</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>11_164_1666</td><td>1666</td><td>203</td><td>86</td><td>-999</td><td>3</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>...</td><td>-999</td><td>-999.0</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td></tr>\n",
              "\t<tr><td>11_164_1689</td><td>1689</td><td>203</td><td>86</td><td>   4</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  20</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   2</td></tr>\n",
              "\t<tr><td>11_164_1713</td><td>1713</td><td>203</td><td>86</td><td>   6</td><td>1</td><td>2001</td><td>  26</td><td>   2</td><td>  16</td><td>...</td><td>2004</td><td> 137.0</td><td>   3</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td></tr>\n",
              "\t<tr><td>12_164_2063</td><td>2063</td><td>203</td><td>86</td><td>  12</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  20</td><td>...</td><td>1998</td><td>  90.0</td><td>   1</td><td>   2</td><td>   1</td><td>   2</td><td>   2</td><td>   1</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>12_164_2109</td><td>2109</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>1997</td><td>  33</td><td>   1</td><td>   8</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td></tr>\n",
              "\t<tr><td>12_164_2133</td><td>2133</td><td>203</td><td>86</td><td>  10</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  15</td><td>...</td><td>2004</td><td>  72.0</td><td>   1</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>13_164_2156</td><td>2156</td><td>203</td><td>86</td><td>   7</td><td>1</td><td>1980</td><td>  13</td><td>   1</td><td>  24</td><td>...</td><td>2004</td><td>  18.0</td><td>   1</td><td>   1</td><td>   1</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   2</td></tr>\n",
              "\t<tr><td>13_164_2179</td><td>2179</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>2009</td><td>  26</td><td>   1</td><td>  12</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>13_164_2203</td><td>2203</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  16</td><td>...</td><td>2004</td><td>  90.0</td><td>   1</td><td>   2</td><td>   2</td><td>   1</td><td>   1</td><td>   3</td><td>   1</td><td>   2</td></tr>\n",
              "\t<tr><td>13_164_2226</td><td>2226</td><td>203</td><td>86</td><td>   7</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  18</td><td>...</td><td>2004</td><td> 137.0</td><td>   3</td><td>   2</td><td>   1</td><td>   1</td><td>   1</td><td>   3</td><td>   3</td><td>   1</td></tr>\n",
              "\t<tr><td>13_164_2249</td><td>2249</td><td>203</td><td>86</td><td>   4</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>   6</td><td>...</td><td>   0</td><td>-999.0</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   1</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>13_164_2272</td><td>2272</td><td>203</td><td>86</td><td>   8</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  20</td><td>...</td><td>2004</td><td>  20.0</td><td>   1</td><td>   2</td><td>   2</td><td>   2</td><td>   2</td><td>   3</td><td>   1</td><td>   2</td></tr>\n",
              "\t<tr><td>13_164_2296</td><td>2296</td><td>203</td><td>86</td><td>  10</td><td>1</td><td>2007</td><td>  26</td><td>   2</td><td>  24</td><td>...</td><td>2004</td><td>  91.0</td><td>   3</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>13_164_2319</td><td>2319</td><td>203</td><td>86</td><td>  12</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  16</td><td>...</td><td>1998</td><td>  91.4</td><td>   3</td><td>   3</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>13_164_2342</td><td>2342</td><td>203</td><td>86</td><td>  12</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  22</td><td>...</td><td>1998</td><td>  78.9</td><td>   1</td><td>   2</td><td>   2</td><td>   3</td><td>   2</td><td>   3</td><td>   3</td><td>   1</td></tr>\n",
              "\t<tr><td>13_164_2366</td><td>2366</td><td>203</td><td>86</td><td>  10</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  12</td><td>...</td><td>1998</td><td>  91.0</td><td>   2</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   1</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>13_164_2376</td><td>2376</td><td>203</td><td>86</td><td>  12</td><td>1</td><td>2012</td><td>  33</td><td>   1</td><td>  20</td><td>...</td><td>1998</td><td>  98.0</td><td>   1</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td></td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
              "\t<tr><td>7_164_1223</td><td>1223</td><td>203</td><td>86</td><td>   6</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  16</td><td>...</td><td>2004</td><td>  18</td><td>   1</td><td>   1</td><td>   1</td><td>   1</td><td>   2</td><td>   1</td><td>   2</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_1286</td><td>1286</td><td>203</td><td>86</td><td>   4</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  32</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_640 </td><td> 640</td><td>203</td><td>86</td><td>  11</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>...</td><td>2004</td><td>  29</td><td>   1</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_757 </td><td> 757</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>   4</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td><td>   9</td></tr>\n",
              "\t<tr><td>7_164_780 </td><td> 780</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>1992</td><td>  15</td><td>   1</td><td>  15</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_788 </td><td> 788</td><td>203</td><td>86</td><td>   6</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  24</td><td>...</td><td>2004</td><td>  45</td><td>   3</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_803 </td><td> 803</td><td>203</td><td>86</td><td>  10</td><td>1</td><td>2001</td><td>  33</td><td>   1</td><td>  12</td><td>...</td><td>2004</td><td> 137</td><td>   3</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   1</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_827 </td><td> 827</td><td>203</td><td>86</td><td>   3</td><td>1</td><td>2004</td><td>  26</td><td>   1</td><td>-999</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   3</td><td>   2</td><td>   3</td><td>   3</td><td>   3</td><td>   3</td><td>   3</td></tr>\n",
              "\t<tr><td>7_164_850 </td><td> 850</td><td>203</td><td>86</td><td>   4</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>   5</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   1</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_873 </td><td> 873</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>   4</td><td>...</td><td>2015</td><td>  15</td><td>   3</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_897 </td><td> 897</td><td>203</td><td>86</td><td>-999</td><td>3</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>...</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td><td>-999</td></tr>\n",
              "\t<tr><td>7_164_920 </td><td> 920</td><td>203</td><td>86</td><td>   8</td><td>1</td><td>1990</td><td>  86</td><td>   1</td><td>  10</td><td>...</td><td>2004</td><td>  48</td><td>   2</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_943 </td><td> 943</td><td>203</td><td>86</td><td>   4</td><td>1</td><td>2006</td><td>  33</td><td>   2</td><td>-999</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td></tr>\n",
              "\t<tr><td>7_164_967 </td><td> 967</td><td>203</td><td>86</td><td>   9</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>   4</td><td>...</td><td>2004</td><td>  36</td><td>   1</td><td>   2</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   2</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_990 </td><td> 990</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>   1</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   3</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>7_164_993 </td><td> 993</td><td>203</td><td>86</td><td>   4</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  16</td><td>...</td><td>2004</td><td>  91</td><td>   3</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>8_164_1899</td><td>1899</td><td>203</td><td>86</td><td>   8</td><td>1</td><td>2004</td><td>  26</td><td>   1</td><td>   4</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>8_164_1923</td><td>1923</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>2003</td><td>  26</td><td>   1</td><td>  10</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   1</td><td>   2</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td></tr>\n",
              "\t<tr><td>8_164_1946</td><td>1946</td><td>203</td><td>86</td><td>   7</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  22</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   1</td><td>   3</td><td>   1</td><td>   2</td></tr>\n",
              "\t<tr><td>8_164_1969</td><td>1969</td><td>203</td><td>86</td><td>   8</td><td>1</td><td>2011</td><td>  26</td><td>   2</td><td>   8</td><td>...</td><td>2004</td><td> 137</td><td>   3</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td></tr>\n",
              "\t<tr><td>8_164_1993</td><td>1993</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>1999</td><td>  67</td><td>   1</td><td>   3</td><td>...</td><td>2015</td><td>  90</td><td>   3</td><td>   2</td><td>   1</td><td>   2</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>8_164_2016</td><td>2016</td><td>203</td><td>86</td><td>   5</td><td>1</td><td>2009</td><td>  33</td><td>   1</td><td>-999</td><td>...</td><td>2004</td><td>  30</td><td>   1</td><td>   2</td><td>   1</td><td>   1</td><td>   1</td><td>   3</td><td>   3</td><td>   1</td></tr>\n",
              "\t<tr><td>8_164_2039</td><td>2039</td><td>203</td><td>86</td><td>  12</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  18</td><td>...</td><td>2004</td><td>  91</td><td>   3</td><td>   1</td><td>   1</td><td>   1</td><td>   3</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>8_164_2086</td><td>2086</td><td>203</td><td>86</td><td>   6</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  14</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   3</td></tr>\n",
              "\t<tr><td>9_164_3962</td><td>3962</td><td>203</td><td>86</td><td>  10</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>   6</td><td>...</td><td>1998</td><td> 116</td><td>   1</td><td>   2</td><td>   1</td><td>   2</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>9_164_3985</td><td>3985</td><td>203</td><td>86</td><td>   6</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  10</td><td>...</td><td>1998</td><td> 150</td><td>   2</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   2</td><td>   3</td><td>   1</td></tr>\n",
              "\t<tr><td>9_164_4009</td><td>4009</td><td>203</td><td>86</td><td>   9</td><td>1</td><td>2013</td><td>  67</td><td>   1</td><td>  24</td><td>...</td><td>1998</td><td>  12</td><td>   1</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>9_164_4032</td><td>4032</td><td>203</td><td>86</td><td>   9</td><td>1</td><td>2013</td><td>  26</td><td>   1</td><td>-999</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   2</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>9_164_4066</td><td>4066</td><td>203</td><td>86</td><td>   9</td><td>1</td><td>-999</td><td>-999</td><td>-999</td><td>  14</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "\t<tr><td>9_164_4131</td><td>4131</td><td>203</td><td>86</td><td>   4</td><td>1</td><td>2010</td><td>  33</td><td>   1</td><td>  14</td><td>...</td><td>   0</td><td>-999</td><td>-999</td><td>   2</td><td>   1</td><td>   1</td><td>   2</td><td>   3</td><td>   1</td><td>   1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.frame: 4383 x 92\n",
              "\\begin{tabular}{lllllllllllllllllllll}\n",
              " H\\_IDNUMBER & HHNO & BEM\\_ID & DIST & TMEM & Q1 & G1\\_4S1 & G1\\_5A1S1 & G1\\_6S1 & P1A\\_2A & ... & P12\\_1 & P12\\_2 & P12\\_3 & Q1\\_1 & Q1\\_3 & Q1\\_5 & Q1\\_6 & Q1\\_11 & Q1\\_12 & Q1\\_13\\\\\n",
              " <fct> & <int> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ... & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
              "\\hline\n",
              "\t 10\\_164\\_3169 & 3169 & 203 & 86 &    5 & 1 & -999 & -999 & -999 &   20 & ... &    0 & -999.0 & -999 &    9 &    9 &    9 &    9 &    9 &    9 &    9\\\\\n",
              "\t 11\\_164\\_1386 & 1386 & 203 & 86 &   11 & 1 & -999 & -999 & -999 &    6 & ... & 1998 &   91.4 &    1 &    3 &    1 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 11\\_164\\_1410 & 1410 & 203 & 86 &   12 & 1 & 1999 &   26 &    2 &   24 & ... & 2004 &   91.0 &    3 &    2 &    1 &    1 &    2 &    1 &    1 &    1\\\\\n",
              "\t 11\\_164\\_1433 & 1433 & 203 & 86 &    8 & 1 & 1995 &   33 &    1 &   10 & ... & 2004 &   97.0 &    2 &    9 &    9 &    9 &    9 &    9 &    9 &    9\\\\\n",
              "\t 11\\_164\\_1456 & 1456 & 203 & 86 &    4 & 1 & 2011 &   59 &    1 &    6 & ... &    0 & -999.0 & -999 &    2 &    1 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 11\\_164\\_1480 & 1480 & 203 & 86 &    4 & 1 & 2002 &   26 &    1 &   10 & ... &    0 & -999.0 & -999 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 11\\_164\\_1503 & 1503 & 203 & 86 &    5 & 1 & 2008 &   26 &    1 &   20 & ... & 2004 &   45.0 &    1 &    1 &    2 &    2 &    1 &    3 &    2 &    2\\\\\n",
              "\t 11\\_164\\_1526 & 1526 & 203 & 86 &    5 & 1 & -999 & -999 & -999 &   12 & ... &    0 & -999.0 & -999 &    2 &    2 &    1 &    2 &    3 &    1 &    2\\\\\n",
              "\t 11\\_164\\_1550 & 1550 & 203 & 86 &    6 & 1 & 2012 &   26 &    1 &    6 & ... &    0 & -999.0 & -999 &    9 &    9 &    9 &    9 &    9 &    9 &    9\\\\\n",
              "\t 11\\_164\\_1573 & 1573 & 203 & 86 &    8 & 1 & 2002 &    6 &    2 &    5 & ... &    0 & -999.0 & -999 &    2 &    1 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 11\\_164\\_1596 & 1596 & 203 & 86 &   12 & 1 & -999 & -999 & -999 &   10 & ... & 1998 &   30.0 &    1 &    2 &    1 &    1 &    2 &    3 &    1 &    2\\\\\n",
              "\t 11\\_164\\_1620 & 1620 & 203 & 86 &   10 & 1 & 2016 &   26 &    1 &   12 & ... & 2004 &   45.0 &    3 &    2 &    2 &    2 &    2 &    3 &    1 &    1\\\\\n",
              "\t 11\\_164\\_1643 & 1643 & 203 & 86 &    5 & 1 & -999 & -999 & -999 &    4 & ... &    0 & -999.0 & -999 &    2 &    1 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 11\\_164\\_1666 & 1666 & 203 & 86 & -999 & 3 & -999 & -999 & -999 & -999 & ... & -999 & -999.0 & -999 & -999 & -999 & -999 & -999 & -999 & -999 & -999\\\\\n",
              "\t 11\\_164\\_1689 & 1689 & 203 & 86 &    4 & 1 & -999 & -999 & -999 &   20 & ... &    0 & -999.0 & -999 &    2 &    2 &    1 &    2 &    3 &    1 &    2\\\\\n",
              "\t 11\\_164\\_1713 & 1713 & 203 & 86 &    6 & 1 & 2001 &   26 &    2 &   16 & ... & 2004 &  137.0 &    3 &    9 &    9 &    9 &    9 &    9 &    9 &    9\\\\\n",
              "\t 12\\_164\\_2063 & 2063 & 203 & 86 &   12 & 1 & -999 & -999 & -999 &   20 & ... & 1998 &   90.0 &    1 &    2 &    1 &    2 &    2 &    1 &    1 &    1\\\\\n",
              "\t 12\\_164\\_2109 & 2109 & 203 & 86 &    5 & 1 & 1997 &   33 &    1 &    8 & ... &    0 & -999.0 & -999 &    2 &    1 &    1 &    2 &    1 &    1 &    2\\\\\n",
              "\t 12\\_164\\_2133 & 2133 & 203 & 86 &   10 & 1 & -999 & -999 & -999 &   15 & ... & 2004 &   72.0 &    1 &    2 &    1 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 13\\_164\\_2156 & 2156 & 203 & 86 &    7 & 1 & 1980 &   13 &    1 &   24 & ... & 2004 &   18.0 &    1 &    1 &    1 &    2 &    2 &    1 &    2 &    2\\\\\n",
              "\t 13\\_164\\_2179 & 2179 & 203 & 86 &    5 & 1 & 2009 &   26 &    1 &   12 & ... &    0 & -999.0 & -999 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 13\\_164\\_2203 & 2203 & 203 & 86 &    5 & 1 & -999 & -999 & -999 &   16 & ... & 2004 &   90.0 &    1 &    2 &    2 &    1 &    1 &    3 &    1 &    2\\\\\n",
              "\t 13\\_164\\_2226 & 2226 & 203 & 86 &    7 & 1 & -999 & -999 & -999 &   18 & ... & 2004 &  137.0 &    3 &    2 &    1 &    1 &    1 &    3 &    3 &    1\\\\\n",
              "\t 13\\_164\\_2249 & 2249 & 203 & 86 &    4 & 1 & -999 & -999 & -999 &    6 & ... &    0 & -999.0 & -999 &    2 &    2 &    1 &    1 &    3 &    1 &    1\\\\\n",
              "\t 13\\_164\\_2272 & 2272 & 203 & 86 &    8 & 1 & -999 & -999 & -999 &   20 & ... & 2004 &   20.0 &    1 &    2 &    2 &    2 &    2 &    3 &    1 &    2\\\\\n",
              "\t 13\\_164\\_2296 & 2296 & 203 & 86 &   10 & 1 & 2007 &   26 &    2 &   24 & ... & 2004 &   91.0 &    3 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 13\\_164\\_2319 & 2319 & 203 & 86 &   12 & 1 & -999 & -999 & -999 &   16 & ... & 1998 &   91.4 &    3 &    3 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 13\\_164\\_2342 & 2342 & 203 & 86 &   12 & 1 & -999 & -999 & -999 &   22 & ... & 1998 &   78.9 &    1 &    2 &    2 &    3 &    2 &    3 &    3 &    1\\\\\n",
              "\t 13\\_164\\_2366 & 2366 & 203 & 86 &   10 & 1 & -999 & -999 & -999 &   12 & ... & 1998 &   91.0 &    2 &    2 &    1 &    1 &    2 &    1 &    1 &    1\\\\\n",
              "\t 13\\_164\\_2376 & 2376 & 203 & 86 &   12 & 1 & 2012 &   33 &    1 &   20 & ... & 1998 &   98.0 &    1 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t ... & ... & ... & ... & ... & ... & ... & ... & ... & ... &  & ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\\n",
              "\t 7\\_164\\_1223 & 1223 & 203 & 86 &    6 & 1 & -999 & -999 & -999 &   16 & ... & 2004 &   18 &    1 &    1 &    1 &    1 &    2 &    1 &    2 &    1\\\\\n",
              "\t 7\\_164\\_1286 & 1286 & 203 & 86 &    4 & 1 & -999 & -999 & -999 &   32 & ... &    0 & -999 & -999 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 7\\_164\\_640  &  640 & 203 & 86 &   11 & 1 & -999 & -999 & -999 & -999 & ... & 2004 &   29 &    1 &    2 &    1 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 7\\_164\\_757  &  757 & 203 & 86 &    5 & 1 & -999 & -999 & -999 &    4 & ... &    0 & -999 & -999 &    9 &    9 &    9 &    9 &    9 &    9 &    9\\\\\n",
              "\t 7\\_164\\_780  &  780 & 203 & 86 &    5 & 1 & 1992 &   15 &    1 &   15 & ... &    0 & -999 & -999 &    2 &    1 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 7\\_164\\_788  &  788 & 203 & 86 &    6 & 1 & -999 & -999 & -999 &   24 & ... & 2004 &   45 &    3 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 7\\_164\\_803  &  803 & 203 & 86 &   10 & 1 & 2001 &   33 &    1 &   12 & ... & 2004 &  137 &    3 &    2 &    1 &    1 &    2 &    1 &    1 &    1\\\\\n",
              "\t 7\\_164\\_827  &  827 & 203 & 86 &    3 & 1 & 2004 &   26 &    1 & -999 & ... &    0 & -999 & -999 &    3 &    2 &    3 &    3 &    3 &    3 &    3\\\\\n",
              "\t 7\\_164\\_850  &  850 & 203 & 86 &    4 & 1 & -999 & -999 & -999 &    5 & ... &    0 & -999 & -999 &    2 &    2 &    1 &    1 &    3 &    1 &    1\\\\\n",
              "\t 7\\_164\\_873  &  873 & 203 & 86 &    5 & 1 & -999 & -999 & -999 &    4 & ... & 2015 &   15 &    3 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 7\\_164\\_897  &  897 & 203 & 86 & -999 & 3 & -999 & -999 & -999 & -999 & ... & -999 & -999 & -999 & -999 & -999 & -999 & -999 & -999 & -999 & -999\\\\\n",
              "\t 7\\_164\\_920  &  920 & 203 & 86 &    8 & 1 & 1990 &   86 &    1 &   10 & ... & 2004 &   48 &    2 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 7\\_164\\_943  &  943 & 203 & 86 &    4 & 1 & 2006 &   33 &    2 & -999 & ... &    0 & -999 & -999 &    2 &    2 &    1 &    2 &    1 &    1 &    2\\\\\n",
              "\t 7\\_164\\_967  &  967 & 203 & 86 &    9 & 1 & -999 & -999 & -999 &    4 & ... & 2004 &   36 &    1 &    2 &    2 &    2 &    1 &    2 &    2 &    1\\\\\n",
              "\t 7\\_164\\_990  &  990 & 203 & 86 &    5 & 1 & -999 & -999 & -999 &    1 & ... &    0 & -999 & -999 &    3 &    1 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 7\\_164\\_993  &  993 & 203 & 86 &    4 & 1 & -999 & -999 & -999 &   16 & ... & 2004 &   91 &    3 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 8\\_164\\_1899 & 1899 & 203 & 86 &    8 & 1 & 2004 &   26 &    1 &    4 & ... &    0 & -999 & -999 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 8\\_164\\_1923 & 1923 & 203 & 86 &    5 & 1 & 2003 &   26 &    1 &   10 & ... &    0 & -999 & -999 &    2 &    1 &    2 &    2 &    2 &    1 &    2\\\\\n",
              "\t 8\\_164\\_1946 & 1946 & 203 & 86 &    7 & 1 & -999 & -999 & -999 &   22 & ... &    0 & -999 & -999 &    2 &    2 &    1 &    1 &    3 &    1 &    2\\\\\n",
              "\t 8\\_164\\_1969 & 1969 & 203 & 86 &    8 & 1 & 2011 &   26 &    2 &    8 & ... & 2004 &  137 &    3 &    2 &    1 &    1 &    2 &    1 &    1 &    2\\\\\n",
              "\t 8\\_164\\_1993 & 1993 & 203 & 86 &    5 & 1 & 1999 &   67 &    1 &    3 & ... & 2015 &   90 &    3 &    2 &    1 &    2 &    2 &    3 &    1 &    1\\\\\n",
              "\t 8\\_164\\_2016 & 2016 & 203 & 86 &    5 & 1 & 2009 &   33 &    1 & -999 & ... & 2004 &   30 &    1 &    2 &    1 &    1 &    1 &    3 &    3 &    1\\\\\n",
              "\t 8\\_164\\_2039 & 2039 & 203 & 86 &   12 & 1 & -999 & -999 & -999 &   18 & ... & 2004 &   91 &    3 &    1 &    1 &    1 &    3 &    3 &    1 &    1\\\\\n",
              "\t 8\\_164\\_2086 & 2086 & 203 & 86 &    6 & 1 & -999 & -999 & -999 &   14 & ... &    0 & -999 & -999 &    2 &    2 &    1 &    2 &    3 &    1 &    3\\\\\n",
              "\t 9\\_164\\_3962 & 3962 & 203 & 86 &   10 & 1 & -999 & -999 & -999 &    6 & ... & 1998 &  116 &    1 &    2 &    1 &    2 &    2 &    3 &    1 &    1\\\\\n",
              "\t 9\\_164\\_3985 & 3985 & 203 & 86 &    6 & 1 & -999 & -999 & -999 &   10 & ... & 1998 &  150 &    2 &    2 &    1 &    1 &    2 &    2 &    3 &    1\\\\\n",
              "\t 9\\_164\\_4009 & 4009 & 203 & 86 &    9 & 1 & 2013 &   67 &    1 &   24 & ... & 1998 &   12 &    1 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 9\\_164\\_4032 & 4032 & 203 & 86 &    9 & 1 & 2013 &   26 &    1 & -999 & ... &    0 & -999 & -999 &    2 &    2 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 9\\_164\\_4066 & 4066 & 203 & 86 &    9 & 1 & -999 & -999 & -999 &   14 & ... &    0 & -999 & -999 &    2 &    1 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\t 9\\_164\\_4131 & 4131 & 203 & 86 &    4 & 1 & 2010 &   33 &    1 &   14 & ... &    0 & -999 & -999 &    2 &    1 &    1 &    2 &    3 &    1 &    1\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.frame: 4383 x 92\n",
              "\n",
              "| H_IDNUMBER &lt;fct&gt; | HHNO &lt;int&gt; | BEM_ID &lt;int&gt; | DIST &lt;dbl&gt; | TMEM &lt;dbl&gt; | Q1 &lt;dbl&gt; | G1_4S1 &lt;dbl&gt; | G1_5A1S1 &lt;dbl&gt; | G1_6S1 &lt;dbl&gt; | P1A_2A &lt;dbl&gt; | ... ... | P12_1 &lt;dbl&gt; | P12_2 &lt;dbl&gt; | P12_3 &lt;dbl&gt; | Q1_1 &lt;dbl&gt; | Q1_3 &lt;dbl&gt; | Q1_5 &lt;dbl&gt; | Q1_6 &lt;dbl&gt; | Q1_11 &lt;dbl&gt; | Q1_12 &lt;dbl&gt; | Q1_13 &lt;dbl&gt; |\n",
              "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
              "| 10_164_3169 | 3169 | 203 | 86 |    5 | 1 | -999 | -999 | -999 |   20 | ... |    0 | -999.0 | -999 |    9 |    9 |    9 |    9 |    9 |    9 |    9 |\n",
              "| 11_164_1386 | 1386 | 203 | 86 |   11 | 1 | -999 | -999 | -999 |    6 | ... | 1998 |   91.4 |    1 |    3 |    1 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 11_164_1410 | 1410 | 203 | 86 |   12 | 1 | 1999 |   26 |    2 |   24 | ... | 2004 |   91.0 |    3 |    2 |    1 |    1 |    2 |    1 |    1 |    1 |\n",
              "| 11_164_1433 | 1433 | 203 | 86 |    8 | 1 | 1995 |   33 |    1 |   10 | ... | 2004 |   97.0 |    2 |    9 |    9 |    9 |    9 |    9 |    9 |    9 |\n",
              "| 11_164_1456 | 1456 | 203 | 86 |    4 | 1 | 2011 |   59 |    1 |    6 | ... |    0 | -999.0 | -999 |    2 |    1 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 11_164_1480 | 1480 | 203 | 86 |    4 | 1 | 2002 |   26 |    1 |   10 | ... |    0 | -999.0 | -999 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 11_164_1503 | 1503 | 203 | 86 |    5 | 1 | 2008 |   26 |    1 |   20 | ... | 2004 |   45.0 |    1 |    1 |    2 |    2 |    1 |    3 |    2 |    2 |\n",
              "| 11_164_1526 | 1526 | 203 | 86 |    5 | 1 | -999 | -999 | -999 |   12 | ... |    0 | -999.0 | -999 |    2 |    2 |    1 |    2 |    3 |    1 |    2 |\n",
              "| 11_164_1550 | 1550 | 203 | 86 |    6 | 1 | 2012 |   26 |    1 |    6 | ... |    0 | -999.0 | -999 |    9 |    9 |    9 |    9 |    9 |    9 |    9 |\n",
              "| 11_164_1573 | 1573 | 203 | 86 |    8 | 1 | 2002 |    6 |    2 |    5 | ... |    0 | -999.0 | -999 |    2 |    1 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 11_164_1596 | 1596 | 203 | 86 |   12 | 1 | -999 | -999 | -999 |   10 | ... | 1998 |   30.0 |    1 |    2 |    1 |    1 |    2 |    3 |    1 |    2 |\n",
              "| 11_164_1620 | 1620 | 203 | 86 |   10 | 1 | 2016 |   26 |    1 |   12 | ... | 2004 |   45.0 |    3 |    2 |    2 |    2 |    2 |    3 |    1 |    1 |\n",
              "| 11_164_1643 | 1643 | 203 | 86 |    5 | 1 | -999 | -999 | -999 |    4 | ... |    0 | -999.0 | -999 |    2 |    1 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 11_164_1666 | 1666 | 203 | 86 | -999 | 3 | -999 | -999 | -999 | -999 | ... | -999 | -999.0 | -999 | -999 | -999 | -999 | -999 | -999 | -999 | -999 |\n",
              "| 11_164_1689 | 1689 | 203 | 86 |    4 | 1 | -999 | -999 | -999 |   20 | ... |    0 | -999.0 | -999 |    2 |    2 |    1 |    2 |    3 |    1 |    2 |\n",
              "| 11_164_1713 | 1713 | 203 | 86 |    6 | 1 | 2001 |   26 |    2 |   16 | ... | 2004 |  137.0 |    3 |    9 |    9 |    9 |    9 |    9 |    9 |    9 |\n",
              "| 12_164_2063 | 2063 | 203 | 86 |   12 | 1 | -999 | -999 | -999 |   20 | ... | 1998 |   90.0 |    1 |    2 |    1 |    2 |    2 |    1 |    1 |    1 |\n",
              "| 12_164_2109 | 2109 | 203 | 86 |    5 | 1 | 1997 |   33 |    1 |    8 | ... |    0 | -999.0 | -999 |    2 |    1 |    1 |    2 |    1 |    1 |    2 |\n",
              "| 12_164_2133 | 2133 | 203 | 86 |   10 | 1 | -999 | -999 | -999 |   15 | ... | 2004 |   72.0 |    1 |    2 |    1 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 13_164_2156 | 2156 | 203 | 86 |    7 | 1 | 1980 |   13 |    1 |   24 | ... | 2004 |   18.0 |    1 |    1 |    1 |    2 |    2 |    1 |    2 |    2 |\n",
              "| 13_164_2179 | 2179 | 203 | 86 |    5 | 1 | 2009 |   26 |    1 |   12 | ... |    0 | -999.0 | -999 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 13_164_2203 | 2203 | 203 | 86 |    5 | 1 | -999 | -999 | -999 |   16 | ... | 2004 |   90.0 |    1 |    2 |    2 |    1 |    1 |    3 |    1 |    2 |\n",
              "| 13_164_2226 | 2226 | 203 | 86 |    7 | 1 | -999 | -999 | -999 |   18 | ... | 2004 |  137.0 |    3 |    2 |    1 |    1 |    1 |    3 |    3 |    1 |\n",
              "| 13_164_2249 | 2249 | 203 | 86 |    4 | 1 | -999 | -999 | -999 |    6 | ... |    0 | -999.0 | -999 |    2 |    2 |    1 |    1 |    3 |    1 |    1 |\n",
              "| 13_164_2272 | 2272 | 203 | 86 |    8 | 1 | -999 | -999 | -999 |   20 | ... | 2004 |   20.0 |    1 |    2 |    2 |    2 |    2 |    3 |    1 |    2 |\n",
              "| 13_164_2296 | 2296 | 203 | 86 |   10 | 1 | 2007 |   26 |    2 |   24 | ... | 2004 |   91.0 |    3 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 13_164_2319 | 2319 | 203 | 86 |   12 | 1 | -999 | -999 | -999 |   16 | ... | 1998 |   91.4 |    3 |    3 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 13_164_2342 | 2342 | 203 | 86 |   12 | 1 | -999 | -999 | -999 |   22 | ... | 1998 |   78.9 |    1 |    2 |    2 |    3 |    2 |    3 |    3 |    1 |\n",
              "| 13_164_2366 | 2366 | 203 | 86 |   10 | 1 | -999 | -999 | -999 |   12 | ... | 1998 |   91.0 |    2 |    2 |    1 |    1 |    2 |    1 |    1 |    1 |\n",
              "| 13_164_2376 | 2376 | 203 | 86 |   12 | 1 | 2012 |   33 |    1 |   20 | ... | 1998 |   98.0 |    1 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | <!----> | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
              "| 7_164_1223 | 1223 | 203 | 86 |    6 | 1 | -999 | -999 | -999 |   16 | ... | 2004 |   18 |    1 |    1 |    1 |    1 |    2 |    1 |    2 |    1 |\n",
              "| 7_164_1286 | 1286 | 203 | 86 |    4 | 1 | -999 | -999 | -999 |   32 | ... |    0 | -999 | -999 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 7_164_640  |  640 | 203 | 86 |   11 | 1 | -999 | -999 | -999 | -999 | ... | 2004 |   29 |    1 |    2 |    1 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 7_164_757  |  757 | 203 | 86 |    5 | 1 | -999 | -999 | -999 |    4 | ... |    0 | -999 | -999 |    9 |    9 |    9 |    9 |    9 |    9 |    9 |\n",
              "| 7_164_780  |  780 | 203 | 86 |    5 | 1 | 1992 |   15 |    1 |   15 | ... |    0 | -999 | -999 |    2 |    1 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 7_164_788  |  788 | 203 | 86 |    6 | 1 | -999 | -999 | -999 |   24 | ... | 2004 |   45 |    3 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 7_164_803  |  803 | 203 | 86 |   10 | 1 | 2001 |   33 |    1 |   12 | ... | 2004 |  137 |    3 |    2 |    1 |    1 |    2 |    1 |    1 |    1 |\n",
              "| 7_164_827  |  827 | 203 | 86 |    3 | 1 | 2004 |   26 |    1 | -999 | ... |    0 | -999 | -999 |    3 |    2 |    3 |    3 |    3 |    3 |    3 |\n",
              "| 7_164_850  |  850 | 203 | 86 |    4 | 1 | -999 | -999 | -999 |    5 | ... |    0 | -999 | -999 |    2 |    2 |    1 |    1 |    3 |    1 |    1 |\n",
              "| 7_164_873  |  873 | 203 | 86 |    5 | 1 | -999 | -999 | -999 |    4 | ... | 2015 |   15 |    3 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 7_164_897  |  897 | 203 | 86 | -999 | 3 | -999 | -999 | -999 | -999 | ... | -999 | -999 | -999 | -999 | -999 | -999 | -999 | -999 | -999 | -999 |\n",
              "| 7_164_920  |  920 | 203 | 86 |    8 | 1 | 1990 |   86 |    1 |   10 | ... | 2004 |   48 |    2 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 7_164_943  |  943 | 203 | 86 |    4 | 1 | 2006 |   33 |    2 | -999 | ... |    0 | -999 | -999 |    2 |    2 |    1 |    2 |    1 |    1 |    2 |\n",
              "| 7_164_967  |  967 | 203 | 86 |    9 | 1 | -999 | -999 | -999 |    4 | ... | 2004 |   36 |    1 |    2 |    2 |    2 |    1 |    2 |    2 |    1 |\n",
              "| 7_164_990  |  990 | 203 | 86 |    5 | 1 | -999 | -999 | -999 |    1 | ... |    0 | -999 | -999 |    3 |    1 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 7_164_993  |  993 | 203 | 86 |    4 | 1 | -999 | -999 | -999 |   16 | ... | 2004 |   91 |    3 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 8_164_1899 | 1899 | 203 | 86 |    8 | 1 | 2004 |   26 |    1 |    4 | ... |    0 | -999 | -999 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 8_164_1923 | 1923 | 203 | 86 |    5 | 1 | 2003 |   26 |    1 |   10 | ... |    0 | -999 | -999 |    2 |    1 |    2 |    2 |    2 |    1 |    2 |\n",
              "| 8_164_1946 | 1946 | 203 | 86 |    7 | 1 | -999 | -999 | -999 |   22 | ... |    0 | -999 | -999 |    2 |    2 |    1 |    1 |    3 |    1 |    2 |\n",
              "| 8_164_1969 | 1969 | 203 | 86 |    8 | 1 | 2011 |   26 |    2 |    8 | ... | 2004 |  137 |    3 |    2 |    1 |    1 |    2 |    1 |    1 |    2 |\n",
              "| 8_164_1993 | 1993 | 203 | 86 |    5 | 1 | 1999 |   67 |    1 |    3 | ... | 2015 |   90 |    3 |    2 |    1 |    2 |    2 |    3 |    1 |    1 |\n",
              "| 8_164_2016 | 2016 | 203 | 86 |    5 | 1 | 2009 |   33 |    1 | -999 | ... | 2004 |   30 |    1 |    2 |    1 |    1 |    1 |    3 |    3 |    1 |\n",
              "| 8_164_2039 | 2039 | 203 | 86 |   12 | 1 | -999 | -999 | -999 |   18 | ... | 2004 |   91 |    3 |    1 |    1 |    1 |    3 |    3 |    1 |    1 |\n",
              "| 8_164_2086 | 2086 | 203 | 86 |    6 | 1 | -999 | -999 | -999 |   14 | ... |    0 | -999 | -999 |    2 |    2 |    1 |    2 |    3 |    1 |    3 |\n",
              "| 9_164_3962 | 3962 | 203 | 86 |   10 | 1 | -999 | -999 | -999 |    6 | ... | 1998 |  116 |    1 |    2 |    1 |    2 |    2 |    3 |    1 |    1 |\n",
              "| 9_164_3985 | 3985 | 203 | 86 |    6 | 1 | -999 | -999 | -999 |   10 | ... | 1998 |  150 |    2 |    2 |    1 |    1 |    2 |    2 |    3 |    1 |\n",
              "| 9_164_4009 | 4009 | 203 | 86 |    9 | 1 | 2013 |   67 |    1 |   24 | ... | 1998 |   12 |    1 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 9_164_4032 | 4032 | 203 | 86 |    9 | 1 | 2013 |   26 |    1 | -999 | ... |    0 | -999 | -999 |    2 |    2 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 9_164_4066 | 4066 | 203 | 86 |    9 | 1 | -999 | -999 | -999 |   14 | ... |    0 | -999 | -999 |    2 |    1 |    1 |    2 |    3 |    1 |    1 |\n",
              "| 9_164_4131 | 4131 | 203 | 86 |    4 | 1 | 2010 |   33 |    1 |   14 | ... |    0 | -999 | -999 |    2 |    1 |    1 |    2 |    3 |    1 |    1 |\n",
              "\n"
            ],
            "text/plain": [
              "     H_IDNUMBER  HHNO BEM_ID DIST TMEM Q1  G1_4S1 G1_5A1S1 G1_6S1 P1A_2A ...\n",
              "1    10_164_3169 3169 203    86      5 1   -999   -999     -999     20   ...\n",
              "2    11_164_1386 1386 203    86     11 1   -999   -999     -999      6   ...\n",
              "3    11_164_1410 1410 203    86     12 1   1999     26        2     24   ...\n",
              "4    11_164_1433 1433 203    86      8 1   1995     33        1     10   ...\n",
              "5    11_164_1456 1456 203    86      4 1   2011     59        1      6   ...\n",
              "6    11_164_1480 1480 203    86      4 1   2002     26        1     10   ...\n",
              "7    11_164_1503 1503 203    86      5 1   2008     26        1     20   ...\n",
              "8    11_164_1526 1526 203    86      5 1   -999   -999     -999     12   ...\n",
              "9    11_164_1550 1550 203    86      6 1   2012     26        1      6   ...\n",
              "10   11_164_1573 1573 203    86      8 1   2002      6        2      5   ...\n",
              "11   11_164_1596 1596 203    86     12 1   -999   -999     -999     10   ...\n",
              "12   11_164_1620 1620 203    86     10 1   2016     26        1     12   ...\n",
              "13   11_164_1643 1643 203    86      5 1   -999   -999     -999      4   ...\n",
              "14   11_164_1666 1666 203    86   -999 3   -999   -999     -999   -999   ...\n",
              "15   11_164_1689 1689 203    86      4 1   -999   -999     -999     20   ...\n",
              "16   11_164_1713 1713 203    86      6 1   2001     26        2     16   ...\n",
              "17   12_164_2063 2063 203    86     12 1   -999   -999     -999     20   ...\n",
              "18   12_164_2109 2109 203    86      5 1   1997     33        1      8   ...\n",
              "19   12_164_2133 2133 203    86     10 1   -999   -999     -999     15   ...\n",
              "20   13_164_2156 2156 203    86      7 1   1980     13        1     24   ...\n",
              "21   13_164_2179 2179 203    86      5 1   2009     26        1     12   ...\n",
              "22   13_164_2203 2203 203    86      5 1   -999   -999     -999     16   ...\n",
              "23   13_164_2226 2226 203    86      7 1   -999   -999     -999     18   ...\n",
              "24   13_164_2249 2249 203    86      4 1   -999   -999     -999      6   ...\n",
              "25   13_164_2272 2272 203    86      8 1   -999   -999     -999     20   ...\n",
              "26   13_164_2296 2296 203    86     10 1   2007     26        2     24   ...\n",
              "27   13_164_2319 2319 203    86     12 1   -999   -999     -999     16   ...\n",
              "28   13_164_2342 2342 203    86     12 1   -999   -999     -999     22   ...\n",
              "29   13_164_2366 2366 203    86     10 1   -999   -999     -999     12   ...\n",
              "30   13_164_2376 2376 203    86     12 1   2012     33        1     20   ...\n",
              "...  ...         ...  ...    ...  ...  ... ...    ...      ...    ...       \n",
              "4354 7_164_1223  1223 203    86      6 1   -999   -999     -999     16   ...\n",
              "4355 7_164_1286  1286 203    86      4 1   -999   -999     -999     32   ...\n",
              "4356 7_164_640    640 203    86     11 1   -999   -999     -999   -999   ...\n",
              "4357 7_164_757    757 203    86      5 1   -999   -999     -999      4   ...\n",
              "4358 7_164_780    780 203    86      5 1   1992     15        1     15   ...\n",
              "4359 7_164_788    788 203    86      6 1   -999   -999     -999     24   ...\n",
              "4360 7_164_803    803 203    86     10 1   2001     33        1     12   ...\n",
              "4361 7_164_827    827 203    86      3 1   2004     26        1   -999   ...\n",
              "4362 7_164_850    850 203    86      4 1   -999   -999     -999      5   ...\n",
              "4363 7_164_873    873 203    86      5 1   -999   -999     -999      4   ...\n",
              "4364 7_164_897    897 203    86   -999 3   -999   -999     -999   -999   ...\n",
              "4365 7_164_920    920 203    86      8 1   1990     86        1     10   ...\n",
              "4366 7_164_943    943 203    86      4 1   2006     33        2   -999   ...\n",
              "4367 7_164_967    967 203    86      9 1   -999   -999     -999      4   ...\n",
              "4368 7_164_990    990 203    86      5 1   -999   -999     -999      1   ...\n",
              "4369 7_164_993    993 203    86      4 1   -999   -999     -999     16   ...\n",
              "4370 8_164_1899  1899 203    86      8 1   2004     26        1      4   ...\n",
              "4371 8_164_1923  1923 203    86      5 1   2003     26        1     10   ...\n",
              "4372 8_164_1946  1946 203    86      7 1   -999   -999     -999     22   ...\n",
              "4373 8_164_1969  1969 203    86      8 1   2011     26        2      8   ...\n",
              "4374 8_164_1993  1993 203    86      5 1   1999     67        1      3   ...\n",
              "4375 8_164_2016  2016 203    86      5 1   2009     33        1   -999   ...\n",
              "4376 8_164_2039  2039 203    86     12 1   -999   -999     -999     18   ...\n",
              "4377 8_164_2086  2086 203    86      6 1   -999   -999     -999     14   ...\n",
              "4378 9_164_3962  3962 203    86     10 1   -999   -999     -999      6   ...\n",
              "4379 9_164_3985  3985 203    86      6 1   -999   -999     -999     10   ...\n",
              "4380 9_164_4009  4009 203    86      9 1   2013     67        1     24   ...\n",
              "4381 9_164_4032  4032 203    86      9 1   2013     26        1   -999   ...\n",
              "4382 9_164_4066  4066 203    86      9 1   -999   -999     -999     14   ...\n",
              "4383 9_164_4131  4131 203    86      4 1   2010     33        1     14   ...\n",
              "     P12_1 P12_2  P12_3 Q1_1 Q1_3 Q1_5 Q1_6 Q1_11 Q1_12 Q1_13\n",
              "1       0  -999.0 -999     9    9    9    9    9     9     9 \n",
              "2    1998    91.4    1     3    1    1    2    3     1     1 \n",
              "3    2004    91.0    3     2    1    1    2    1     1     1 \n",
              "4    2004    97.0    2     9    9    9    9    9     9     9 \n",
              "5       0  -999.0 -999     2    1    1    2    3     1     1 \n",
              "6       0  -999.0 -999     2    2    1    2    3     1     1 \n",
              "7    2004    45.0    1     1    2    2    1    3     2     2 \n",
              "8       0  -999.0 -999     2    2    1    2    3     1     2 \n",
              "9       0  -999.0 -999     9    9    9    9    9     9     9 \n",
              "10      0  -999.0 -999     2    1    1    2    3     1     1 \n",
              "11   1998    30.0    1     2    1    1    2    3     1     2 \n",
              "12   2004    45.0    3     2    2    2    2    3     1     1 \n",
              "13      0  -999.0 -999     2    1    1    2    3     1     1 \n",
              "14   -999  -999.0 -999  -999 -999 -999 -999 -999  -999  -999 \n",
              "15      0  -999.0 -999     2    2    1    2    3     1     2 \n",
              "16   2004   137.0    3     9    9    9    9    9     9     9 \n",
              "17   1998    90.0    1     2    1    2    2    1     1     1 \n",
              "18      0  -999.0 -999     2    1    1    2    1     1     2 \n",
              "19   2004    72.0    1     2    1    1    2    3     1     1 \n",
              "20   2004    18.0    1     1    1    2    2    1     2     2 \n",
              "21      0  -999.0 -999     2    2    1    2    3     1     1 \n",
              "22   2004    90.0    1     2    2    1    1    3     1     2 \n",
              "23   2004   137.0    3     2    1    1    1    3     3     1 \n",
              "24      0  -999.0 -999     2    2    1    1    3     1     1 \n",
              "25   2004    20.0    1     2    2    2    2    3     1     2 \n",
              "26   2004    91.0    3     2    2    1    2    3     1     1 \n",
              "27   1998    91.4    3     3    2    1    2    3     1     1 \n",
              "28   1998    78.9    1     2    2    3    2    3     3     1 \n",
              "29   1998    91.0    2     2    1    1    2    1     1     1 \n",
              "30   1998    98.0    1     2    2    1    2    3     1     1 \n",
              "...  ...   ...    ...   ...  ...  ...  ...  ...   ...   ...  \n",
              "4354 2004    18      1     1    1    1    2    1     2     1 \n",
              "4355    0  -999   -999     2    2    1    2    3     1     1 \n",
              "4356 2004    29      1     2    1    1    2    3     1     1 \n",
              "4357    0  -999   -999     9    9    9    9    9     9     9 \n",
              "4358    0  -999   -999     2    1    1    2    3     1     1 \n",
              "4359 2004    45      3     2    2    1    2    3     1     1 \n",
              "4360 2004   137      3     2    1    1    2    1     1     1 \n",
              "4361    0  -999   -999     3    2    3    3    3     3     3 \n",
              "4362    0  -999   -999     2    2    1    1    3     1     1 \n",
              "4363 2015    15      3     2    2    1    2    3     1     1 \n",
              "4364 -999  -999   -999  -999 -999 -999 -999 -999  -999  -999 \n",
              "4365 2004    48      2     2    2    1    2    3     1     1 \n",
              "4366    0  -999   -999     2    2    1    2    1     1     2 \n",
              "4367 2004    36      1     2    2    2    1    2     2     1 \n",
              "4368    0  -999   -999     3    1    1    2    3     1     1 \n",
              "4369 2004    91      3     2    2    1    2    3     1     1 \n",
              "4370    0  -999   -999     2    2    1    2    3     1     1 \n",
              "4371    0  -999   -999     2    1    2    2    2     1     2 \n",
              "4372    0  -999   -999     2    2    1    1    3     1     2 \n",
              "4373 2004   137      3     2    1    1    2    1     1     2 \n",
              "4374 2015    90      3     2    1    2    2    3     1     1 \n",
              "4375 2004    30      1     2    1    1    1    3     3     1 \n",
              "4376 2004    91      3     1    1    1    3    3     1     1 \n",
              "4377    0  -999   -999     2    2    1    2    3     1     3 \n",
              "4378 1998   116      1     2    1    2    2    3     1     1 \n",
              "4379 1998   150      2     2    1    1    2    2     3     1 \n",
              "4380 1998    12      1     2    2    1    2    3     1     1 \n",
              "4381    0  -999   -999     2    2    1    2    3     1     1 \n",
              "4382    0  -999   -999     2    1    1    2    3     1     1 \n",
              "4383    0  -999   -999     2    1    1    2    3     1     1 "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [1] \"(Intercept)\" \"TMEM\"        \"P5_1\"        \"J2_1\"        \"J2_14\"      \n",
            " [6] \"J1AB\"        \"T2\"          \"Q1_1\"        \"Q1_3\"        \"Q1_5\"       \n",
            "[11] \"Q1_13\"      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in chisq.test(df[, categorical_cols], df$Q1_1):\n",
            "\"Chi-squared approximation may be incorrect\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "character(0)\n"
          ]
        }
      ],
      "source": [
        "library(randomForest)\n",
        "library(caret)\n",
        "library(stats)\n",
        "library(glmnet)\n",
        "library(rpart)\n",
        "library(gbm)\n",
        "library(caret)\n",
        "library(rpart)\n",
        "library(xgboost)\n",
        "df = read.csv(\"/Users/sheebamoghal/Desktop/DSAN_5300/5300-project-bangladesh_migration/cleaned_data/new-cleaned_data-01.csv\")\n",
        "\n",
        "\n",
        "# Seperate Numerical and Categorical Data \n",
        "numeric_cols = sapply(df, is.numeric)\n",
        "categorical_cols = !numeric_cols\n",
        "# Ensure categorical columns are factors \n",
        "df[categorical_cols] = lapply(df[categorical_cols], factor)\n",
        "\n",
        "# Check any missing values\n",
        "#df[is.na(df)] = -999\n",
        "df[is.na(df)] = -999\n",
        "View(df)\n",
        "\n",
        "# Feature selection for Numerical Feature\n",
        "\n",
        "# L1 (Lasso) Regularization \n",
        "x = as.matrix(df[, numeric_cols])\n",
        "y = df$Q1_1\n",
        "lasso_model = cv.glmnet(x, y, alpha = 1, nfolds =10)\n",
        "coef_lasso = coef(lasso_model, s = \"lambda.min\")\n",
        "numeric_lasso = rownames(coef_lasso)[coef_lasso[,1] != 0]\n",
        "print(numeric_lasso)\n",
        "\n",
        "# Feature Selection for Catgorical Features \n",
        "\n",
        "# Chi-Square test \n",
        "chi_squared = chisq.test(df[, categorical_cols], df$Q1_1)\n",
        "p_value = chi_squared$p.value\n",
        "significant_categorical = names(df)[categorical_cols][p_value < 0.05]\n",
        "print(significant_categorical)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Selected Features found using Q1_1 as the target Y variable \n",
        "# Q1_1: Perceived Environmental Change: Temperature\n",
        "\n",
        "\n",
        "\n",
        "# TMEM: Total household member\n",
        "# P5_1: Land Holdings: Does household cultivate aquaculture?\n",
        "# J2_1: House Services: Light\n",
        "# J2_14: House Services: Generator\n",
        "# J1AB: Energy: Used by household? - Fire wood\n",
        "# T2: Government/Aid: Local government officials are effective?\n",
        "# Q1_1: Perceived Environmental Change: Temperature\n",
        "# Q1_3: Perceived Environmental Change: Rainfall during other seasons\n",
        "# Q1_5: Perceived Environmental Change: Severity of floods\n",
        "# Q1_13: Perceived Environmental Change: Abundance of fish in water\n",
        "\n",
        "# Cleaned Data set with selected features using Q1_1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " [1] \"(Intercept)\" \"TMEM\"        \"P5_1\"        \"J2_1\"        \"J2_14\"      \n",
        " [6] \"J1AB\"        \"T2\"          \"Q1_1\"        \"Q1_3\"        \"Q1_5\"       \n",
        "[11] \"Q1_13\"  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [1] \"(Intercept)\" \"TMEM\"        \"P5_1\"        \"J2_1\"        \"J2_14\"      \n",
            " [6] \"J1AB\"        \"T2\"          \"Q1_1\"        \"Q1_3\"        \"Q1_5\"       \n",
            "[11] \"Q1_13\"      \n"
          ]
        }
      ],
      "source": [
        "# Combine selected features\n",
        "selected_features = c(numeric_lasso, significant_categorical)\n",
        "print(selected_features)\n",
        "\n",
        "\n",
        "library(dplyr)\n",
        "df = df %>% select(TMEM, P5_1, J2_1, J2_14, J1AB, T2, Q1_1, Q1_3, Q1_5, Q1_13)\n",
        "df[df == -999] = 0.01\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# This should be regression analysis to predict enviromental change in Q1_1 as a continious variable based on what selected predictors we have. \n",
        "\n",
        "\n",
        "\n",
        "## OLD CODE: can use if needed\n",
        "# Feature selction attempt using PCA\n",
        "#pca_result = prcomp(df[, numeric_cols & !(names(df) %in% c(\"HHNO\", \"BEM_ID\"))], scale. = TRUE)\n",
        "#pca_feat = pca_result$x[, 1:10]\n",
        "#ctrl = rfeControl(functions = rfFuncs, method = \"cv\", number = 10)\n",
        "##feature_sel = rfe(pca_feat, df$Q1_1, sizes = c(1:5), rfeControl = ctrl)\n",
        "#print(feature_sel)\n",
        "\n",
        "# create model training \n",
        "#train_index = createDataPartition(df$Q1_1, p = 0.8, list = FALSE)\n",
        "#train_data = df[train_index, ]\n",
        "#test_data = df[-train_index, ]\n",
        "\n",
        "# Random forest\n",
        "#rf_model = randomForest(Q1_1 ~ ., data = train_data[, !(names(df) %in% c(\"HHNO\", \"BEM_ID\"))], ntree = 500 )\n",
        "\n",
        "# Create prediction using test set\n",
        "#pred = predict(rf_model, test_data[, !(names(df) %in% c(\"HHNO\", \"BEM_ID\"))])\n",
        "\n",
        "# Create confusion matrix \n",
        "#conf_matrix = table(pred, test_data$Q1_1)\n",
        "#print(conf_matrix)\n",
        "#acc = sum(diag(conf_matrix)) / sum(conf_matrix)\n",
        "#print(acc)\n",
        "\n",
        "# Visual results \n",
        "#plot(pca_result)\n",
        "#varImpPlot(rf_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# [for variable exploration]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 x 10</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>TMEM</th><th scope=col>P5_1</th><th scope=col>J2_1</th><th scope=col>J2_14</th><th scope=col>J1AB</th><th scope=col>T2</th><th scope=col>Q1_1</th><th scope=col>Q1_3</th><th scope=col>Q1_5</th><th scope=col>Q1_13</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td> 5</td><td>2</td><td>1</td><td>2</td><td>1</td><td>9</td><td>9</td><td>9</td><td>9</td><td>9</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>11</td><td>2</td><td>1</td><td>2</td><td>1</td><td>3</td><td>3</td><td>1</td><td>1</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>12</td><td>2</td><td>1</td><td>2</td><td>1</td><td>2</td><td>2</td><td>1</td><td>1</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>4</th><td> 8</td><td>2</td><td>1</td><td>2</td><td>1</td><td>9</td><td>9</td><td>9</td><td>9</td><td>9</td></tr>\n",
              "\t<tr><th scope=row>5</th><td> 4</td><td>2</td><td>1</td><td>2</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>6</th><td> 4</td><td>2</td><td>1</td><td>2</td><td>1</td><td>2</td><td>2</td><td>2</td><td>1</td><td>1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.frame: 6 x 10\n",
              "\\begin{tabular}{r|llllllllll}\n",
              "  & TMEM & P5\\_1 & J2\\_1 & J2\\_14 & J1AB & T2 & Q1\\_1 & Q1\\_3 & Q1\\_5 & Q1\\_13\\\\\n",
              "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
              "\\hline\n",
              "\t1 &  5 & 2 & 1 & 2 & 1 & 9 & 9 & 9 & 9 & 9\\\\\n",
              "\t2 & 11 & 2 & 1 & 2 & 1 & 3 & 3 & 1 & 1 & 1\\\\\n",
              "\t3 & 12 & 2 & 1 & 2 & 1 & 2 & 2 & 1 & 1 & 1\\\\\n",
              "\t4 &  8 & 2 & 1 & 2 & 1 & 9 & 9 & 9 & 9 & 9\\\\\n",
              "\t5 &  4 & 2 & 1 & 2 & 1 & 1 & 2 & 1 & 1 & 1\\\\\n",
              "\t6 &  4 & 2 & 1 & 2 & 1 & 2 & 2 & 2 & 1 & 1\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.frame: 6 x 10\n",
              "\n",
              "| <!--/--> | TMEM &lt;dbl&gt; | P5_1 &lt;dbl&gt; | J2_1 &lt;dbl&gt; | J2_14 &lt;dbl&gt; | J1AB &lt;dbl&gt; | T2 &lt;dbl&gt; | Q1_1 &lt;dbl&gt; | Q1_3 &lt;dbl&gt; | Q1_5 &lt;dbl&gt; | Q1_13 &lt;dbl&gt; |\n",
              "|---|---|---|---|---|---|---|---|---|---|---|\n",
              "| 1 |  5 | 2 | 1 | 2 | 1 | 9 | 9 | 9 | 9 | 9 |\n",
              "| 2 | 11 | 2 | 1 | 2 | 1 | 3 | 3 | 1 | 1 | 1 |\n",
              "| 3 | 12 | 2 | 1 | 2 | 1 | 2 | 2 | 1 | 1 | 1 |\n",
              "| 4 |  8 | 2 | 1 | 2 | 1 | 9 | 9 | 9 | 9 | 9 |\n",
              "| 5 |  4 | 2 | 1 | 2 | 1 | 1 | 2 | 1 | 1 | 1 |\n",
              "| 6 |  4 | 2 | 1 | 2 | 1 | 2 | 2 | 2 | 1 | 1 |\n",
              "\n"
            ],
            "text/plain": [
              "  TMEM P5_1 J2_1 J2_14 J1AB T2 Q1_1 Q1_3 Q1_5 Q1_13\n",
              "1  5   2    1    2     1    9  9    9    9    9    \n",
              "2 11   2    1    2     1    3  3    1    1    1    \n",
              "3 12   2    1    2     1    2  2    1    1    1    \n",
              "4  8   2    1    2     1    9  9    9    9    9    \n",
              "5  4   2    1    2     1    1  2    1    1    1    \n",
              "6  4   2    1    2     1    2  2    2    1    1    "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "head(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'TMEM'</li><li>'P5_1'</li><li>'J2_1'</li><li>'J2_14'</li><li>'J1AB'</li><li>'T2'</li><li>'Q1_1'</li><li>'Q1_3'</li><li>'Q1_5'</li><li>'Q1_13'</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 'TMEM'\n",
              "\\item 'P5\\_1'\n",
              "\\item 'J2\\_1'\n",
              "\\item 'J2\\_14'\n",
              "\\item 'J1AB'\n",
              "\\item 'T2'\n",
              "\\item 'Q1\\_1'\n",
              "\\item 'Q1\\_3'\n",
              "\\item 'Q1\\_5'\n",
              "\\item 'Q1\\_13'\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 'TMEM'\n",
              "2. 'P5_1'\n",
              "3. 'J2_1'\n",
              "4. 'J2_14'\n",
              "5. 'J1AB'\n",
              "6. 'T2'\n",
              "7. 'Q1_1'\n",
              "8. 'Q1_3'\n",
              "9. 'Q1_5'\n",
              "10. 'Q1_13'\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              " [1] \"TMEM\"  \"P5_1\"  \"J2_1\"  \"J2_14\" \"J1AB\"  \"T2\"    \"Q1_1\"  \"Q1_3\"  \"Q1_5\" \n",
              "[10] \"Q1_13\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "colnames(df) # going to use these specific columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.3980601 \n",
            "MAE: 0.2771514 \n",
            "R-squared: 0.9470258 \n"
          ]
        }
      ],
      "source": [
        "y = df$Q1_1\n",
        "x = df[, c('TMEM', 'P5_1', 'J2_1', 'J2_14', 'J1AB', 'T2', 'Q1_3', 'Q1_5', 'Q1_13')]\n",
        "\n",
        "set.seed(123)  \n",
        "train_index = createDataPartition(y, p = 0.8, list = FALSE)\n",
        "train_x = x[train_index, ]\n",
        "train_y = y[train_index]\n",
        "test_x = x[-train_index, ]\n",
        "test_y = y[-train_index]\n",
        "\n",
        "lm_model = lm(train_y ~ ., data = train_x)\n",
        "test_pred = predict(lm_model, newdata = test_x)\n",
        "rmse = sqrt(mean((test_y - test_pred)^2))\n",
        "mae = mean(abs(test_y - test_pred))\n",
        "r_squared = cor(test_y, test_pred)^2\n",
        "cat(\"RMSE:\", rmse, \"\\n\")\n",
        "cat(\"MAE:\", mae, \"\\n\")\n",
        "cat(\"R-squared:\", r_squared, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "lm(formula = train_y ~ ., data = train_x)\n",
              "\n",
              "Residuals:\n",
              "     Min       1Q   Median       3Q      Max \n",
              "-1.94922 -0.16054  0.05209  0.27346  1.39880 \n",
              "\n",
              "Coefficients:\n",
              "              Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)  0.0120641  0.0235208   0.513    0.608    \n",
              "TMEM         0.0003285  0.0031393   0.105    0.917    \n",
              "P5_1         0.0447571  0.0287925   1.554    0.120    \n",
              "J2_1        -0.0063632  0.0315272  -0.202    0.840    \n",
              "J2_14        0.2936384  0.0346132   8.483   <2e-16 ***\n",
              "J1AB         0.0160226  0.0233392   0.687    0.492    \n",
              "T2           0.1036131  0.0088688  11.683   <2e-16 ***\n",
              "Q1_3         0.2364077  0.0115860  20.405   <2e-16 ***\n",
              "Q1_5         0.2239284  0.0121718  18.397   <2e-16 ***\n",
              "Q1_13        0.3434541  0.0122258  28.093   <2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
              "\n",
              "Residual standard error: 0.4154 on 3497 degrees of freedom\n",
              "Multiple R-squared:  0.9397,\tAdjusted R-squared:  0.9395 \n",
              "F-statistic:  6051 on 9 and 3497 DF,  p-value: < 2.2e-16\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "summary(lm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "source": [
        "With this, it is interesting to see how the having a generator, and changes in enironment due to rainfall, floods and fish affects the decision on environmental change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "source": [
        "# LR (with significant variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.3980373 \n",
            "MAE: 0.277325 \n",
            "R-squared: 0.9470285 \n"
          ]
        }
      ],
      "source": [
        "lm_model = lm(train_y ~ J2_14 + T2 + Q1_3 + Q1_5 + Q1_13 , data = train_x)\n",
        "test_pred = predict(lm_model, newdata = test_x)\n",
        "rmse = sqrt(mean((test_y - test_pred)^2))\n",
        "mae = mean(abs(test_y - test_pred))\n",
        "r_squared = cor(test_y, test_pred)^2\n",
        "cat(\"RMSE:\", rmse, \"\\n\")\n",
        "cat(\"MAE:\", mae, \"\\n\")\n",
        "cat(\"R-squared:\", r_squared, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's almost the same with and without. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# user defined function for metrics\n",
        "calculate_metrics = function(test_y, test_pred) {\n",
        "  rmse = sqrt(mean((test_y - test_pred)^2))\n",
        "  mae = mean(abs(test_y - test_pred))\n",
        "  r_squared = cor(test_y, test_pred)^2\n",
        "  return(list(RMSE = rmse, MAE = mae, R_squared = r_squared))\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline LR "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "lm_model = lm(train_y ~ ., data = train_x)\n",
        "lm_pred = predict(lm_model, newdata = test_x)\n",
        "lm_metrics = calculate_metrics(test_y, lm_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ridge Regression "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ridge_model = cv.glmnet(as.matrix(train_x), train_y, alpha = 0)\n",
        "ridge_pred = predict(ridge_model, newx = as.matrix(test_x))\n",
        "ridge_metrics = calculate_metrics(test_y, ridge_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lasso Regression "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "lasso_model = cv.glmnet(as.matrix(train_x), train_y, alpha = 1)\n",
        "lasso_pred = predict(lasso_model, newx = as.matrix(test_x))\n",
        "lasso_metrics = calculate_metrics(test_y, lasso_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Elastic Net Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "enet_model = cv.glmnet(as.matrix(train_x), train_y, alpha = 0.5)\n",
        "enet_pred = predict(enet_model, newx = as.matrix(test_x))\n",
        "enet_metrics = calculate_metrics(test_y, enet_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "source": [
        "# GLM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$RMSE\n",
            "[1] 0.3980601\n",
            "\n",
            "$MAE\n",
            "[1] 0.2771514\n",
            "\n",
            "$R_squared\n",
            "[1] 0.9470258\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load required libraries\n",
        "library(caret)\n",
        "\n",
        "# Train the GLM model\n",
        "glm_model = train(\n",
        "  x = train_x,\n",
        "  y = train_y,\n",
        "  method = \"glm\",  # Example method: Generalized Linear Model\n",
        "  trControl = trainControl(method = \"cv\", number = 5)\n",
        ")\n",
        "\n",
        "# Generate predictions from the GLM model\n",
        "glm_pred = predict(glm_model, newdata = test_x)\n",
        "\n",
        "# Calculate evaluation metrics for the GLM model\n",
        "glm_metrics = calculate_metrics(test_y, glm_pred)\n",
        "\n",
        "print(glm_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Decision Tree (Base Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "dt_model = rpart(train_y ~ ., data = train_x)\n",
        "dt_pred = predict(dt_model, newdata = test_x)\n",
        "dt_metrics = calculate_metrics(test_y, dt_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "source": [
        "# Decision Tree (Hyperparameter Tuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    cp\n",
            "10 0.1\n",
            "[1] \"Decision Tree (Hyperparameter Tuned using GridSearchCV)\"\n",
            "$RMSE\n",
            "[1] 0.3181162\n",
            "\n",
            "$MAE\n",
            "[1] 0.131386\n",
            "\n",
            "$R_squared\n",
            "[1] 0.9661455\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# grid\n",
        "grid = expand.grid(cp = seq(0.01, 0.5, 0.01))\n",
        "\n",
        "dt_tuned = train(\n",
        "  x = train_x,\n",
        "  y = train_y,\n",
        "  method = \"rpart\",\n",
        "  trControl = trainControl(method = \"cv\", number = 5),\n",
        "  tuneGrid = grid\n",
        ")\n",
        "\n",
        "print(dt_tuned$bestTune)\n",
        "dt_tuned_pred = predict(dt_tuned, newdata = test_x)\n",
        "dt_tuned_metrics = calculate_metrics(test_y, dt_tuned_pred)\n",
        "print(\"Decision Tree (Hyperparameter Tuned using GridSearchCV)\")\n",
        "print(dt_tuned_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Forest (Base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in randomForest.default(m, y, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n"
          ]
        }
      ],
      "source": [
        "rf_model = randomForest(train_y ~ ., data = train_x)\n",
        "rf_pred = predict(rf_model, newdata = test_x)\n",
        "rf_metrics = calculate_metrics(test_y, rf_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Forest (Hyperparameter Tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  mtry\n",
            "1    2\n",
            "[1] \"Random Forest (Hyperparameter Tuned using GridSearchCV)\"\n",
            "$RMSE\n",
            "[1] 0.3198054\n",
            "\n",
            "$MAE\n",
            "[1] 0.140746\n",
            "\n",
            "$R_squared\n",
            "[1] 0.9657908\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# tuning \n",
        "grid = expand.grid(mtry = c(2, 3, 4))  \n",
        "\n",
        "rf_tuned = train(\n",
        "  x = train_x,\n",
        "  y = train_y,\n",
        "  method = \"rf\",\n",
        "  trControl = trainControl(method = \"cv\", number = 2),\n",
        "  tuneGrid = grid\n",
        ")\n",
        "\n",
        "print(rf_tuned$bestTune)\n",
        "rf_tuned_pred = predict(rf_tuned, newdata = test_x)\n",
        "rf_tuned_metrics = calculate_metrics(test_y, rf_tuned_pred)\n",
        "print(\"Random Forest (Hyperparameter Tuned using GridSearchCV)\")\n",
        "print(rf_tuned_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Adaboost (didn't use since it is mostly for classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "source": [
        "# Gradient Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using 739 trees...\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] \"Gradient Boosting\"\n",
            "$RMSE\n",
            "[1] 0.320142\n",
            "\n",
            "$MAE\n",
            "[1] 0.1407959\n",
            "\n",
            "$R_squared\n",
            "[1] 0.9657212\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "gbm_model = gbm(\n",
        "  formula = train_y ~ .,\n",
        "  data = train_x,\n",
        "  distribution = \"gaussian\",  # i chose gaussian\n",
        "  n.trees = 1000,  \n",
        "  interaction.depth = 4,  \n",
        "  shrinkage = 0.01,  # this is learning rate\n",
        "  bag.fraction = 0.5,  \n",
        "  cv.folds = 5  #cv\n",
        ")\n",
        "\n",
        "\n",
        "gbm_pred = predict(gbm_model, newdata = test_x)\n",
        "gbm_metrics = calculate_metrics(test_y, gbm_pred)\n",
        "print(\"Gradient Boosting\")\n",
        "print(gbm_metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\ttrain-rmse:1.665661 \n",
            "[2]\ttrain-rmse:1.190726 \n",
            "[3]\ttrain-rmse:0.866603 \n",
            "[4]\ttrain-rmse:0.649860 \n",
            "[5]\ttrain-rmse:0.510686 \n",
            "[6]\ttrain-rmse:0.424065 \n",
            "[7]\ttrain-rmse:0.374066 \n",
            "[8]\ttrain-rmse:0.346893 \n",
            "[9]\ttrain-rmse:0.332304 \n",
            "[10]\ttrain-rmse:0.323964 \n",
            "[11]\ttrain-rmse:0.319907 \n",
            "[12]\ttrain-rmse:0.316472 \n",
            "[13]\ttrain-rmse:0.314834 \n",
            "[14]\ttrain-rmse:0.313960 \n",
            "[15]\ttrain-rmse:0.312839 \n",
            "[16]\ttrain-rmse:0.311948 \n",
            "[17]\ttrain-rmse:0.310875 \n",
            "[18]\ttrain-rmse:0.309837 \n",
            "[19]\ttrain-rmse:0.309115 \n",
            "[20]\ttrain-rmse:0.307473 \n",
            "[21]\ttrain-rmse:0.306207 \n",
            "[22]\ttrain-rmse:0.304935 \n",
            "[23]\ttrain-rmse:0.304225 \n",
            "[24]\ttrain-rmse:0.303665 \n",
            "[25]\ttrain-rmse:0.303057 \n",
            "[26]\ttrain-rmse:0.302364 \n",
            "[27]\ttrain-rmse:0.301923 \n",
            "[28]\ttrain-rmse:0.301270 \n",
            "[29]\ttrain-rmse:0.300770 \n",
            "[30]\ttrain-rmse:0.300526 \n",
            "[31]\ttrain-rmse:0.300028 \n",
            "[32]\ttrain-rmse:0.299797 \n",
            "[33]\ttrain-rmse:0.299510 \n",
            "[34]\ttrain-rmse:0.299283 \n",
            "[35]\ttrain-rmse:0.298860 \n",
            "[36]\ttrain-rmse:0.298129 \n",
            "[37]\ttrain-rmse:0.297677 \n",
            "[38]\ttrain-rmse:0.297540 \n",
            "[39]\ttrain-rmse:0.297290 \n",
            "[40]\ttrain-rmse:0.296835 \n",
            "[41]\ttrain-rmse:0.296723 \n",
            "[42]\ttrain-rmse:0.296395 \n",
            "[43]\ttrain-rmse:0.295809 \n",
            "[44]\ttrain-rmse:0.295552 \n",
            "[45]\ttrain-rmse:0.295341 \n",
            "[46]\ttrain-rmse:0.295105 \n",
            "[47]\ttrain-rmse:0.294796 \n",
            "[48]\ttrain-rmse:0.294423 \n",
            "[49]\ttrain-rmse:0.293926 \n",
            "[50]\ttrain-rmse:0.293748 \n",
            "[51]\ttrain-rmse:0.293499 \n",
            "[52]\ttrain-rmse:0.293265 \n",
            "[53]\ttrain-rmse:0.292987 \n",
            "[54]\ttrain-rmse:0.292687 \n",
            "[55]\ttrain-rmse:0.292517 \n",
            "[56]\ttrain-rmse:0.292436 \n",
            "[57]\ttrain-rmse:0.292261 \n",
            "[58]\ttrain-rmse:0.292140 \n",
            "[59]\ttrain-rmse:0.292250 \n",
            "[60]\ttrain-rmse:0.292036 \n",
            "[61]\ttrain-rmse:0.291941 \n",
            "[62]\ttrain-rmse:0.291738 \n",
            "[63]\ttrain-rmse:0.291662 \n",
            "[64]\ttrain-rmse:0.291519 \n",
            "[65]\ttrain-rmse:0.291155 \n",
            "[66]\ttrain-rmse:0.290634 \n",
            "[67]\ttrain-rmse:0.290439 \n",
            "[68]\ttrain-rmse:0.290330 \n",
            "[69]\ttrain-rmse:0.290260 \n",
            "[70]\ttrain-rmse:0.290148 \n",
            "[71]\ttrain-rmse:0.289824 \n",
            "[72]\ttrain-rmse:0.289696 \n",
            "[73]\ttrain-rmse:0.289562 \n",
            "[74]\ttrain-rmse:0.289525 \n",
            "[75]\ttrain-rmse:0.289504 \n",
            "[76]\ttrain-rmse:0.289339 \n",
            "[77]\ttrain-rmse:0.289060 \n",
            "[78]\ttrain-rmse:0.288900 \n",
            "[79]\ttrain-rmse:0.288843 \n",
            "[80]\ttrain-rmse:0.288730 \n",
            "[81]\ttrain-rmse:0.288675 \n",
            "[82]\ttrain-rmse:0.288572 \n",
            "[83]\ttrain-rmse:0.288414 \n",
            "[84]\ttrain-rmse:0.288387 \n",
            "[85]\ttrain-rmse:0.288429 \n",
            "[86]\ttrain-rmse:0.288344 \n",
            "[87]\ttrain-rmse:0.288302 \n",
            "[88]\ttrain-rmse:0.288233 \n",
            "[89]\ttrain-rmse:0.288199 \n",
            "[90]\ttrain-rmse:0.288059 \n",
            "[91]\ttrain-rmse:0.287995 \n",
            "[92]\ttrain-rmse:0.287724 \n",
            "[93]\ttrain-rmse:0.287549 \n",
            "[94]\ttrain-rmse:0.287447 \n",
            "[95]\ttrain-rmse:0.287253 \n",
            "[96]\ttrain-rmse:0.287182 \n",
            "[97]\ttrain-rmse:0.287153 \n",
            "[98]\ttrain-rmse:0.286978 \n",
            "[99]\ttrain-rmse:0.286980 \n",
            "[100]\ttrain-rmse:0.286925 \n",
            "[1] \"XGBoost\"\n",
            "$RMSE\n",
            "[1] 0.3492329\n",
            "\n",
            "$MAE\n",
            "[1] 0.1791548\n",
            "\n",
            "$R_squared\n",
            "[1] 0.9592438\n",
            "\n"
          ]
        }
      ],
      "source": [
        "xgb_model = xgboost(\n",
        "  data = as.matrix(train_x),\n",
        "  label = train_y,\n",
        "  nrounds = 100,  # n boosting rounds \n",
        "  objective = \"reg:squarederror\",  # obj fn\n",
        "  eta = 0.3,  # lr\n",
        "  max_depth = 6,  \n",
        "  subsample = 0.8,  \n",
        "  colsample_bytree = 0.8)\n",
        "\n",
        "xgb_pred = predict(xgb_model, as.matrix(test_x))\n",
        "xgb_metrics = calculate_metrics(test_y, xgb_pred)\n",
        "\n",
        "print(\"XGBoost\")\n",
        "print(xgb_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stacked Model (using GLM and Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n",
            "Warning message in randomForest.default(x, y, mtry = param$mtry, ...):\n",
            "\"The response has five or fewer unique values.  Are you sure you want to do regression?\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] \"Stacked Model\"\n",
            "$RMSE\n",
            "[1] 0.3195356\n",
            "\n",
            "$MAE\n",
            "[1] 0.1461466\n",
            "\n",
            "$R_squared\n",
            "[1] 0.9658408\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model1 = train(\n",
        "  x = train_x,\n",
        "  y = train_y,\n",
        "  method = \"glm\", # using glm\n",
        "  trControl = trainControl(method = \"cv\", number = 5)\n",
        ")\n",
        "\n",
        "model2 = train(\n",
        "  x = train_x,\n",
        "  y = train_y,\n",
        "  method = \"rf\",  # random forest\n",
        "  trControl = trainControl(method = \"cv\", number = 5)\n",
        ")\n",
        "\n",
        "pred_model1 = predict(model1, newdata = test_x)\n",
        "pred_model2 = predict(model2, newdata = test_x)\n",
        "\n",
        "stacked_data = data.frame(pred_model1, pred_model2)\n",
        "\n",
        "stacked_model = lm(test_y ~ ., data = stacked_data)\n",
        "stacked_pred = predict(stacked_model, newdata = stacked_data)\n",
        "stacked_metrics = calculate_metrics(test_y, stacked_pred)\n",
        "print(\"Stacked Model\")\n",
        "print(stacked_metrics)\n",
        "\n",
        "# dont worry about the warniing messages since the number of columns are v less lol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Tabular Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                  Model      RMSE       MAE R_squared\n",
            "1          Base Linear Regression (OLS) 0.3980601 0.2771514 0.9470258\n",
            "2                      Ridge Regression 0.4172933 0.2939489 0.9439985\n",
            "3                      Lasso Regression 0.4078301 0.3019748 0.9462018\n",
            "4                Elastic Net Regression 0.4064160 0.2967684 0.9461558\n",
            "5                  Decision Tree (Base) 0.3181162 0.1313860 0.9661455\n",
            "6                  Random Forest (Base) 0.3253209 0.1503552 0.9646005\n",
            "7  Decision Tree (Hyperparameter Tuned) 0.3181162 0.1313860 0.9661455\n",
            "8  Random Forest (Hyperparameter Tuned) 0.3198989 0.1409187 0.9657753\n",
            "9                     Gradient Boosting 0.3203697 0.1422168 0.9656845\n",
            "10                              XGBoost 0.3480966 0.1797902 0.9595205\n",
            "11                        Stacked Model 0.3189486 0.1461091 0.9659662\n"
          ]
        }
      ],
      "source": [
        "\n",
        "models = c(\"Base Linear Regression (OLS)\", \"Ridge Regression\", \"Lasso Regression\", \n",
        "            \"Elastic Net Regression\", \"Decision Tree (Base)\", \"Random Forest (Base)\", \n",
        "            \"Decision Tree (Hyperparameter Tuned)\", \"Random Forest (Hyperparameter Tuned)\",\n",
        "            \"Gradient Boosting\", \"XGBoost\", \"Stacked Model\")\n",
        "predictions = list(\n",
        "  lm_pred, ridge_pred, lasso_pred, enet_pred, dt_pred, rf_pred, dt_tuned_pred,\n",
        "  rf_tuned_pred, gbm_pred, xgb_pred, stacked_pred\n",
        ")\n",
        "\n",
        "metrics_table = data.frame(\n",
        "  Model = models,\n",
        "  RMSE = numeric(length(models)),\n",
        "  MAE = numeric(length(models)),\n",
        "  R_squared = numeric(length(models))\n",
        ")\n",
        "\n",
        "calculate_and_fill_metrics = function(test_y, test_pred) {\n",
        "  rmse = sqrt(mean((test_y - test_pred)^2))\n",
        "  mae = mean(abs(test_y - test_pred))\n",
        "  r_squared = cor(test_y, test_pred)^2\n",
        "  return(c(RMSE = rmse, MAE = mae, R_squared = r_squared))\n",
        "}\n",
        "\n",
        "for (i in 1:length(models)) {\n",
        "  metrics = calculate_and_fill_metrics(test_y, predictions[[i]])\n",
        "  metrics_table[i, 2:4] = metrics\n",
        "}\n",
        "\n",
        "print(metrics_table)\n",
        "metrics_table = rbind(metrics_table, c(\"GLM Model\", glm_metrics$RMSE, glm_metrics$MAE, glm_metrics$R_squared))\n",
        "print(metrics_table)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.3.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
